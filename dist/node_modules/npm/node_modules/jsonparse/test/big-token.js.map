{"version":3,"sources":["../../../../../../node_modules/npm/node_modules/jsonparse/test/big-token.js"],"names":["stream","require","JsonParse","test","t","parser","chunkSize","chunks","quote","Buffer","from","plan","onToken","type","value","equal","length","end","write","i","buf","alloc","fill"],"mappings":";;AAAA,IAAIA,SAASC,QAAQ,QAAR,CAAb;AACA,IAAIC,YAAYD,QAAQ,cAAR,CAAhB;AACA,IAAIE,OAAOF,QAAQ,MAAR,CAAX;;AAEAE,KAAK,uDAAL,EAA8D,UAAUC,CAAV,EAAa;AACzE,MAAIC,SAAS,IAAIH,SAAJ,EAAb;AACA,MAAII,YAAY,IAAhB;AACA,MAAIC,SAAS,OAAO,GAApB,CAHyE,CAGhD;AACzB,MAAIC,QAAQC,OAAOC,IAAP,GAAcD,OAAOC,IAAP,CAAY,GAAZ,CAAd,GAAiC,IAAID,MAAJ,CAAW,GAAX,CAA7C;AACAL,IAAEO,IAAF,CAAO,CAAP;;AAEAN,SAAOO,OAAP,GAAiB,UAAUC,IAAV,EAAgBC,KAAhB,EAAuB;AACtCV,MAAEW,KAAF,CAAQD,MAAME,MAAd,EAAsBV,YAAYC,MAAlC,EAA0C,oCAA1C;AACAH,MAAEa,GAAF;AACD,GAHD;;AAKAZ,SAAOa,KAAP,CAAaV,KAAb;AACA,OAAK,IAAIW,IAAI,CAAb,EAAgBA,IAAIZ,MAApB,EAA4B,EAAEY,CAA9B,EAAiC;AAC/B,QAAIC,MAAMX,OAAOY,KAAP,GAAeZ,OAAOY,KAAP,CAAaf,SAAb,CAAf,GAAyC,IAAIG,MAAJ,CAAWH,SAAX,CAAnD;AACAc,QAAIE,IAAJ,CAAS,GAAT;AACAjB,WAAOa,KAAP,CAAaE,GAAb;AACD;AACDf,SAAOa,KAAP,CAAaV,KAAb;AACD,CAnBD","file":"big-token.js","sourcesContent":["var stream = require('stream');\nvar JsonParse = require('../jsonparse');\nvar test = require('tape');\n\ntest('can handle large tokens without running out of memory', function (t) {\n  var parser = new JsonParse();\n  var chunkSize = 1024;\n  var chunks = 1024 * 200; // 200mb\n  var quote = Buffer.from ? Buffer.from('\"') : new Buffer('\"');\n  t.plan(1);\n\n  parser.onToken = function (type, value) {\n    t.equal(value.length, chunkSize * chunks, 'token should be size of input json');\n    t.end();\n  };\n\n  parser.write(quote);\n  for (var i = 0; i < chunks; ++i) {\n    var buf = Buffer.alloc ? Buffer.alloc(chunkSize) : new Buffer(chunkSize);\n    buf.fill('a');\n    parser.write(buf);\n  }\n  parser.write(quote);\n});\n"]}